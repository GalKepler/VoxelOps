{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSIRecon Basics: Diffusion MRI Reconstruction\n",
    "\n",
    "This notebook demonstrates how to use the QSIRecon runner for diffusion reconstruction and connectivity analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "QSIRecon performs:\n",
    "- Diffusion model fitting (DTI, CSD, MAPMRI, etc.)\n",
    "- Tractography\n",
    "- Structural connectivity matrix generation\n",
    "- Regional quantification\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Docker installed and running\n",
    "- QSIPrep preprocessed data\n",
    "- Reconstruction specification file (JSON/YAML)\n",
    "- FreeSurfer license file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from voxelops import (\n",
    "    run_qsirecon,\n",
    "    QSIReconInputs,\n",
    "    QSIReconDefaults,\n",
    ")\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "qsiprep_dir = Path(\"/media/storage/yalab-dev/qsiprep_test/qsiprep_output/\")\n",
    "participant = \"01\"\n",
    "recon_spec = Path(\"/home/galkepler/Projects/yalab-devops/VoxelOps/qsirecon_spec.yaml\")\n",
    "fs_license = Path(\"/home/galkepler/misc/freesurfer/license.txt\")\n",
    "\n",
    "# Output paths (optional)\n",
    "output_dir = Path(\"/media/storage/yalab-dev/qsiprep_test/qsirecon_output/\")\n",
    "work_dir = Path(\"/media/storage/yalab-dev/qsiprep_test/work/qsirecon/\")\n",
    "\n",
    "# Datasets to include\n",
    "datasets = {\n",
    "    \"atlases\": \"/media/storage/yalab-dev/voxelops/Schaefer2018Tian2020_atlases\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Reconstruction Specs\n",
    "\n",
    "QSIRecon requires a reconstruction specification file that defines:\n",
    "- Which diffusion models to fit\n",
    "- Tractography algorithms to use\n",
    "- Parcellation schemes for connectivity\n",
    "- Atlas registrations\n",
    "\n",
    "Common specs:\n",
    "- `dsi_studio_gqi`: DSI Studio's GQI model with tractography\n",
    "- `mrtrix_multishell_msmt_ACT-fast`: Multi-shell MSMT-CSD with ACT\n",
    "- `amico_noddi`: AMICO NODDI model fitting\n",
    "- `dipy_mapmri`: DIPY MAPMRI reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Specification:\n",
      "name: gal_multishell_scalars\n",
      "nodes:\n",
      "- action: DKI_reconstruction\n",
      "  name: dipy_dki\n",
      "  parameters:\n",
      "    wmti: true\n",
      "    write_fibgz: false\n",
      "    write_mif: false\n",
      "  qsirecon_suffix: DIPYDKI\n",
      "  software: Dipy\n",
      "- action: fit_noddi\n",
      "  name: amico_noddi\n",
      "  parameters:\n",
      "    dIso: 0.003\n",
      "    dPar: 0.0017\n",
      "    isExvivo: false\n",
      "  qsirecon_suffix: AMICONODDI\n",
      "  software: AMICO\n",
      "- action: MAPMRI_reconstruction\n",
      "  name: dipy_mapmri\n",
      "  parameters:\n",
      "    anisotropic_scaling: false\n",
      "    big_delta: null\n",
      "    bval_threshold: 2000\n",
      "    dti_scale_estimation: false\n",
      "    laplacian_regularization: true\n",
      "    laplacian_weighting: 0.2\n",
      "    radial_order: 6\n",
      "    small_delta: null\n",
      "    write_fibgz: true\n",
      "    write_mif: true\n",
      "  qsirecon_suffix: DIPYMAPMRI\n",
      "  software: Dipy\n",
      "- action: reconstruction\n",
      "  input: qsirecon\n",
      "  name: dsistudio_gqi\n",
      "  parameters:\n",
      "    method: gqi\n",
      "  qsirecon_suffix: DSIStudio\n",
      "  software: DSI Studio\n",
      "- action: export\n",
      "  input: dsistudio_gqi\n",
      "  name: scalar_export\n",
      "  qsirecon_suffix: DSIStudio\n",
      "  software: DSI Studio\n",
      "- action: template_map\n",
      "  input: qsirecon\n",
      "  name: template_map\n",
      "  parameters:\n",
      "    interpolation: Linear\n",
      "  scalars_from:\n",
      "  - dipy_dki\n",
      "  - amico_noddi\n",
      "  - dipy_mapmri\n",
      "  - scalar_export\n",
      "  software: qsirecon\n",
      "space: T1w\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View reconstruction spec (yaml file)\n",
    "import yaml\n",
    "\n",
    "if recon_spec.exists():\n",
    "    spec_content = yaml.safe_load(recon_spec.read_text())\n",
    "    print(\"Reconstruction Specification:\")\n",
    "    print(yaml.dump(spec_content, indent=2))\n",
    "else:\n",
    "    print(f\"Recon spec not found: {recon_spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "### Option 1: Use Default Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running qsirecon for participant 01\n",
      "================================================================================\n",
      "Command: docker run -it --rm --user 1000:1000 -v /media/storage/yalab-dev/qsiprep_test/qsiprep_output:/data:ro -v /media/storage/yalab-dev/qsiprep_test/qsirecon_output:/out -v /media/storage/yalab-dev/qsiprep_test/work/qsirecon:/work -v /home/galkepler/Projects/yalab-devops/VoxelOps/qsirecon_spec.yaml:/recon_spec.yaml:ro -v /home/galkepler/misc/freesurfer/license.txt:/license.txt:ro -v /media/storage/yalab-dev/voxelops/Schaefer2018Tian2020_atlases:/datasets/atlases:ro pennlinc/qsirecon:1.1.1 /data /out participant --participant-label 01 --nprocs 8 --mem-mb 16000 --work-dir /work --datasets atlases=/datasets/atlases --atlases 4S156Parcels 4S256Parcels 4S356Parcels 4S456Parcels 4S556Parcels 4S656Parcels 4S756Parcels 4S856Parcels 4S956Parcels 4S1056Parcels AICHA384Ext Brainnetome246Ext AAL116 Gordon333Ext Schaefer2018N100n7Tian2020S1 Schaefer2018N100n7Tian2020S2 Schaefer2018N100n7Tian2020S3 Schaefer2018N100n7Tian2020S4 Schaefer2018N200n7Tian2020S1 Schaefer2018N200n7Tian2020S2 Schaefer2018N200n7Tian2020S3 Schaefer2018N200n7Tian2020S4 Schaefer2018N300n7Tian2020S1 Schaefer2018N300n7Tian2020S2 Schaefer2018N300n7Tian2020S3 Schaefer2018N300n7Tian2020S4 Schaefer2018N400n7Tian2020S1 Schaefer2018N400n7Tian2020S2 Schaefer2018N400n7Tian2020S3 Schaefer2018N400n7Tian2020S4 Schaefer2018N500n7Tian2020S1 Schaefer2018N500n7Tian2020S2 Schaefer2018N500n7Tian2020S3 Schaefer2018N500n7Tian2020S4 Schaefer2018N600n7Tian2020S1 Schaefer2018N600n7Tian2020S2 Schaefer2018N600n7Tian2020S3 Schaefer2018N600n7Tian2020S4 Schaefer2018N800n7Tian2020S1 Schaefer2018N800n7Tian2020S2 Schaefer2018N800n7Tian2020S3 Schaefer2018N800n7Tian2020S4 Schaefer2018N900n7Tian2020S1 Schaefer2018N900n7Tian2020S2 Schaefer2018N900n7Tian2020S3 Schaefer2018N900n7Tian2020S4 Schaefer2018N1000n7Tian2020S1 Schaefer2018N1000n7Tian2020S2 Schaefer2018N1000n7Tian2020S3 Schaefer2018N1000n7Tian2020S4 --recon-spec /recon_spec.yaml --fs-license-file /license.txt\n",
      "================================================================================\n",
      "\n",
      "Execution log saved: /media/storage/yalab-dev/qsiprep_test/logs/qsirecon_01_20260201_181503.json\n"
     ]
    },
    {
     "ename": "ProcedureExecutionError",
     "evalue": "qsirecon failed: qsirecon failed with exit code 1\n\nStderr (last 1000 chars):\nthe input device is not a TTY\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProcedureExecutionError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m      2\u001b[39m inputs = QSIReconInputs(\n\u001b[32m      3\u001b[39m     qsiprep_dir=qsiprep_dir,\n\u001b[32m      4\u001b[39m     participant=participant,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mSchaefer2018N1000n7Tian2020S4\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Run with defaults\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m result = \u001b[43mrun_qsirecon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_license\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs_license\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocker_image\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpennlinc/qsirecon:1.1.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     50\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccess: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mduration_human\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/yalab-devops/VoxelOps/src/voxelops/runners/qsirecon.py:152\u001b[39m, in \u001b[36mrun_qsirecon\u001b[39m\u001b[34m(inputs, config, **overrides)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Execute\u001b[39;00m\n\u001b[32m    151\u001b[39m log_dir = output_dir.parent / \u001b[33m\"\u001b[39m\u001b[33mlogs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m result = \u001b[43mrun_docker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqsirecon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Add inputs, config, and expected outputs to result\u001b[39;00m\n\u001b[32m    160\u001b[39m result[\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m] = inputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/yalab-devops/VoxelOps/src/voxelops/runners/_base.py:148\u001b[39m, in \u001b[36mrun_docker\u001b[39m\u001b[34m(cmd, tool_name, participant, log_dir, capture_output)\u001b[39m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    146\u001b[39m             json.dump(record, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProcedureExecutionError(\n\u001b[32m    149\u001b[39m         procedure_name=tool_name,\n\u001b[32m    150\u001b[39m         message=error_msg,\n\u001b[32m    151\u001b[39m     )\n\u001b[32m    153\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mProcedureExecutionError\u001b[39m: qsirecon failed: qsirecon failed with exit code 1\n\nStderr (last 1000 chars):\nthe input device is not a TTY\n"
     ]
    }
   ],
   "source": [
    "# Create inputs\n",
    "inputs = QSIReconInputs(\n",
    "    qsiprep_dir=qsiprep_dir,\n",
    "    participant=participant,\n",
    "    recon_spec=recon_spec,\n",
    "    output_dir=output_dir,\n",
    "    work_dir=work_dir,\n",
    "    datasets=datasets,\n",
    "    atlases=['Schaefer2018N100n7Tian2020S1',\n",
    " 'Schaefer2018N100n7Tian2020S2',\n",
    " 'Schaefer2018N100n7Tian2020S3',\n",
    " 'Schaefer2018N100n7Tian2020S4',\n",
    " 'Schaefer2018N200n7Tian2020S1',\n",
    " 'Schaefer2018N200n7Tian2020S2',\n",
    " 'Schaefer2018N200n7Tian2020S3',\n",
    " 'Schaefer2018N200n7Tian2020S4',\n",
    " 'Schaefer2018N300n7Tian2020S1',\n",
    " 'Schaefer2018N300n7Tian2020S2',\n",
    " 'Schaefer2018N300n7Tian2020S3',\n",
    " 'Schaefer2018N300n7Tian2020S4',\n",
    " 'Schaefer2018N400n7Tian2020S1',\n",
    " 'Schaefer2018N400n7Tian2020S2',\n",
    " 'Schaefer2018N400n7Tian2020S3',\n",
    " 'Schaefer2018N400n7Tian2020S4',\n",
    " 'Schaefer2018N500n7Tian2020S1',\n",
    " 'Schaefer2018N500n7Tian2020S2',\n",
    " 'Schaefer2018N500n7Tian2020S3',\n",
    " 'Schaefer2018N500n7Tian2020S4',\n",
    " 'Schaefer2018N600n7Tian2020S1',\n",
    " 'Schaefer2018N600n7Tian2020S2',\n",
    " 'Schaefer2018N600n7Tian2020S3',\n",
    " 'Schaefer2018N600n7Tian2020S4',\n",
    " 'Schaefer2018N800n7Tian2020S1',\n",
    " 'Schaefer2018N800n7Tian2020S2',\n",
    " 'Schaefer2018N800n7Tian2020S3',\n",
    " 'Schaefer2018N800n7Tian2020S4',\n",
    " 'Schaefer2018N900n7Tian2020S1',\n",
    " 'Schaefer2018N900n7Tian2020S2',\n",
    " 'Schaefer2018N900n7Tian2020S3',\n",
    " 'Schaefer2018N900n7Tian2020S4',\n",
    " 'Schaefer2018N1000n7Tian2020S1',\n",
    " 'Schaefer2018N1000n7Tian2020S2',\n",
    " 'Schaefer2018N1000n7Tian2020S3',\n",
    " 'Schaefer2018N1000n7Tian2020S4']\n",
    ")\n",
    "\n",
    "# Run with defaults\n",
    "result = run_qsirecon(\n",
    "    inputs, fs_license=fs_license, docker_image=\"pennlinc/qsirecon:1.1.1\"\n",
    ")\n",
    "\n",
    "print(f\"Success: {result['success']}\")\n",
    "print(f\"Duration: {result['duration_human']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Increase Resources for Tractography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tractography is computationally intensive\n",
    "result = run_qsirecon(\n",
    "    inputs,\n",
    "    fs_license=fs_license,\n",
    "    nprocs=32,  # More cores = faster tractography\n",
    "    mem_gb=64,  # Sufficient memory for large atlases\n",
    ")\n",
    "\n",
    "print(f\"Success: {result['success']}\")\n",
    "print(f\"Processing time: {result['duration_human']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Custom Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "config = QSIReconDefaults(\n",
    "    nprocs=24,\n",
    "    mem_gb=48,\n",
    "    skip_bids_validation=False,\n",
    "    fs_license=fs_license,\n",
    "    docker_image=\"pennlinc/qsirecon:0.19.1\",  # Pin version\n",
    ")\n",
    "\n",
    "result = run_qsirecon(inputs, config)\n",
    "\n",
    "print(f\"Success: {result['success']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Execution Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution Details:\")\n",
    "print(f\"  Tool: {result['tool']}\")\n",
    "print(f\"  Participant: {result['participant']}\")\n",
    "print(f\"  Duration: {result['duration_human']}\")\n",
    "print(f\"  Success: {result['success']}\")\n",
    "\n",
    "print(\"\\nConfiguration Used:\")\n",
    "config_used = result[\"config\"]\n",
    "print(f\"  Cores: {config_used.nprocs}\")\n",
    "print(f\"  Memory: {config_used.mem_gb}GB\")\n",
    "print(f\"  Docker image: {config_used.docker_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Expected Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = result[\"expected_outputs\"]\n",
    "\n",
    "print(\"Expected Output Locations:\")\n",
    "print(f\"  QSIRecon directory: {outputs.qsirecon_dir}\")\n",
    "print(f\"  Participant directory: {outputs.participant_dir}\")\n",
    "print(f\"  HTML report: {outputs.html_report}\")\n",
    "print(f\"  Work directory: {outputs.work_dir}\")\n",
    "\n",
    "# Verify outputs\n",
    "print(\"\\nOutput Validation:\")\n",
    "print(f\"  HTML report exists: {outputs.html_report.exists()}\")\n",
    "print(f\"  Participant dir exists: {outputs.participant_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Reconstruction Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outputs.participant_dir.exists():\n",
    "    print(f\"Reconstruction outputs for {participant}:\\n\")\n",
    "\n",
    "    # Organize by type\n",
    "    scalar_maps = []\n",
    "    tractography = []\n",
    "    connectivity = []\n",
    "    other = []\n",
    "\n",
    "    for f in outputs.participant_dir.rglob(\"*\"):\n",
    "        if f.is_file():\n",
    "            name = f.name\n",
    "            if name.endswith(\".nii.gz\"):\n",
    "                scalar_maps.append(f)\n",
    "            elif name.endswith((\".trk\", \".tck\", \".fib\")):\n",
    "                tractography.append(f)\n",
    "            elif name.endswith(\".csv\"):\n",
    "                connectivity.append(f)\n",
    "            else:\n",
    "                other.append(f)\n",
    "\n",
    "    print(f\"Scalar Maps ({len(scalar_maps)}):\")\n",
    "    for f in sorted(scalar_maps)[:10]:  # Show first 10\n",
    "        print(f\"  {f.name}\")\n",
    "\n",
    "    print(f\"\\nTractography Files ({len(tractography)}):\")\n",
    "    for f in sorted(tractography):\n",
    "        print(f\"  {f.name} ({f.stat().st_size / (1024**2):.1f} MB)\")\n",
    "\n",
    "    print(f\"\\nConnectivity Matrices ({len(connectivity)}):\")\n",
    "    for f in sorted(connectivity):\n",
    "        print(f\"  {f.name}\")\n",
    "else:\n",
    "    print(\"Participant directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize Connectivity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Find connectivity matrices\n",
    "connectivity_files = list(outputs.participant_dir.rglob(\"*connectivity*.csv\"))\n",
    "\n",
    "if connectivity_files:\n",
    "    # Load first connectivity matrix\n",
    "    conn_file = connectivity_files[0]\n",
    "    print(f\"Loading: {conn_file.name}\\n\")\n",
    "\n",
    "    # Load matrix\n",
    "    conn_matrix = pd.read_csv(conn_file, index_col=0)\n",
    "\n",
    "    print(f\"Matrix shape: {conn_matrix.shape}\")\n",
    "    print(f\"ROIs: {len(conn_matrix)}\")\n",
    "    print(f\"\\nFirst few ROI names:\")\n",
    "    print(conn_matrix.index[:5].tolist())\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(conn_matrix.values, cmap=\"hot\", interpolation=\"nearest\")\n",
    "    plt.colorbar(label=\"Connection Strength\")\n",
    "    plt.title(f\"Structural Connectivity Matrix\\n{conn_file.name}\")\n",
    "    plt.xlabel(\"ROI Index\")\n",
    "    plt.ylabel(\"ROI Index\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Basic statistics\n",
    "    print(f\"\\nMatrix Statistics:\")\n",
    "    print(f\"  Mean connection strength: {conn_matrix.values.mean():.4f}\")\n",
    "    print(f\"  Max connection strength: {conn_matrix.values.max():.4f}\")\n",
    "    print(f\"  Sparsity: {(conn_matrix.values == 0).sum() / conn_matrix.size:.1%}\")\n",
    "else:\n",
    "    print(\"No connectivity matrices found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View HTML QC Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "if outputs.html_report.exists():\n",
    "    IFrame(src=str(outputs.html_report), width=900, height=600)\n",
    "else:\n",
    "    print(f\"HTML report not found: {outputs.html_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Multiple Reconstruction Specs\n",
    "\n",
    "You might want to run different reconstruction pipelines on the same data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple reconstruction specs\n",
    "recon_specs = [\n",
    "    Path(\"/config/recon_specs/dsi_studio_gqi.json\"),\n",
    "    Path(\"/config/recon_specs/mrtrix_msmt_csd.json\"),\n",
    "    Path(\"/config/recon_specs/amico_noddi.json\"),\n",
    "]\n",
    "\n",
    "config = QSIReconDefaults(\n",
    "    nprocs=24,\n",
    "    mem_gb=48,\n",
    "    fs_license=fs_license,\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for spec in recon_specs:\n",
    "    if not spec.exists():\n",
    "        print(f\"Skipping {spec.name} (not found)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nRunning reconstruction: {spec.stem}\")\n",
    "\n",
    "    inputs = QSIReconInputs(\n",
    "        qsiprep_dir=qsiprep_dir,\n",
    "        participant=participant,\n",
    "        recon_spec=spec,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = run_qsirecon(inputs, config)\n",
    "        results.append(result)\n",
    "        print(f\"  ✓ Success in {result['duration_human']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "        results.append({\"recon_spec\": spec.name, \"success\": False, \"error\": str(e)})\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nCompleted {len(results)} reconstructions\")\n",
    "for r in results:\n",
    "    if r.get(\"success\"):\n",
    "        print(f\"  ✓ {r['inputs'].recon_spec.stem}: {r['duration_human']}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {r.get('recon_spec', 'unknown')}: Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxelops.exceptions import (\n",
    "    ProcedureExecutionError,\n",
    "    InputValidationError,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = run_qsirecon(\n",
    "        inputs,\n",
    "        fs_license=fs_license,\n",
    "        nprocs=24,\n",
    "    )\n",
    "    print(f\"Success: {result['success']}\")\n",
    "\n",
    "except InputValidationError as e:\n",
    "    print(f\"Input validation failed: {e}\")\n",
    "    print(\"Common issues:\")\n",
    "    print(\"  - QSIPrep directory doesn't exist\")\n",
    "    print(\"  - Participant not found in QSIPrep output\")\n",
    "    print(\"  - Reconstruction spec file not found or invalid\")\n",
    "\n",
    "except ProcedureExecutionError as e:\n",
    "    print(f\"Execution failed: {e}\")\n",
    "    print(f\"Check logs: {result.get('log_file')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After QSIRecon reconstruction:\n",
    "\n",
    "1. Review the HTML QC report\n",
    "2. Inspect connectivity matrices\n",
    "3. Visualize tractography (using DSI Studio, TrackVis, etc.)\n",
    "4. Run parcellation with QSIParc (see `04_qsiparc_basics.ipynb`)\n",
    "5. Perform network analysis on connectivity matrices\n",
    "\n",
    "## Tips\n",
    "\n",
    "- **Reconstruction specs**: Choose based on your acquisition (single-shell vs multi-shell)\n",
    "- **Resources**: Tractography is CPU-intensive - allocate sufficient cores\n",
    "- **Memory**: Some atlases require significant memory (64GB+ for high-resolution)\n",
    "- **Validation**: Always review the HTML report for quality control\n",
    "- **Multiple specs**: You can run different models on the same preprocessed data\n",
    "- **Connectivity matrices**: Different atlases produce different sized matrices\n",
    "- **Version pinning**: Use specific Docker versions for reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VoxelOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
